{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d56cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of y_train before SMOTE: is_goal\n",
      "0    758\n",
      "1     42\n",
      "Name: count, dtype: int64\n",
      "Distribution of y_train after SMOTE: is_goal\n",
      "0    758\n",
      "1    758\n",
      "Name: count, dtype: int64\n",
      "Results for Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.89       188\n",
      "           1       0.19      0.67      0.29        12\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.58      0.74      0.59       200\n",
      "weighted avg       0.93      0.81      0.85       200\n",
      "\n",
      "ROC AUC Score: 0.8754432624113475\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       188\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.47      0.50      0.48       200\n",
      "weighted avg       0.88      0.94      0.91       200\n",
      "\n",
      "ROC AUC Score: 0.7865691489361702\n",
      "---------------------------\n",
      "\n",
      "Results for SVM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       188\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.47      0.49      0.48       200\n",
      "weighted avg       0.88      0.92      0.90       200\n",
      "\n",
      "ROC AUC Score: 0.7938829787234043\n",
      "---------------------------\n",
      "\n",
      "[22:29:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Results for Gradient Boosted Trees (XGBoost):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       188\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.47      0.49      0.48       200\n",
      "weighted avg       0.88      0.93      0.91       200\n",
      "\n",
      "ROC AUC Score: 0.74822695035461\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Gradient Boosted Trees (LightGBM):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       188\n",
      "           1       0.12      0.08      0.10        12\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.53      0.52      0.53       200\n",
      "weighted avg       0.89      0.91      0.90       200\n",
      "\n",
      "ROC AUC Score: 0.8280141843971631\n",
      "---------------------------\n",
      "\n",
      "Results for Gradient Boosted Trees (CatBoost):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       188\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.47      0.50      0.48       200\n",
      "weighted avg       0.88      0.94      0.91       200\n",
      "\n",
      "ROC AUC Score: 0.7699468085106383\n",
      "---------------------------\n",
      "\n",
      "The best model is: Logistic Regression with ROC AUC: 0.8754\n",
      "\n",
      "Players ranked from best shooting ability to worst using the best model:\n",
      "1. Player 3 with average goal probability: 0.2674\n",
      "2. Player 4 with average goal probability: 0.2077\n",
      "3. Player 1 with average goal probability: 0.1884\n",
      "4. Player 2 with average goal probability: 0.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, \n",
    "accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('shotData.csv')\n",
    "\n",
    "# One hot encoding\n",
    "one_hot_columns = ['locationOnNet', 'manpowerSituation', \n",
    "                   'shotType', 'ozEntryType', 'entryType', \n",
    "                   'precedingEventOneType', 'precedingEventTwoType', \n",
    "                   'precedingEventThreeType', 'period', 'strength']\n",
    "df = pd.get_dummies(df, columns=one_hot_columns, drop_first=True)\n",
    "\n",
    "# Label encoding for binary columns\n",
    "label_encoders = {}\n",
    "for column in ['screen', 'shooterUnderPressure', 'oneTimer', 'lastFaceoffOutcome']:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Handle deflection columns\n",
    "df['deflection'] = ~df['deflectionX'].isna() * 1\n",
    "df = df.drop(columns=['deflectionX', 'deflectionY'])\n",
    "\n",
    "df['is_goal'] = df['shotResult'].apply(lambda x: 1 if x == 'goal' else 0)\n",
    "X = df.drop(columns=['shotResult', 'is_goal', 'playerId'])\n",
    "y = df['is_goal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imputation for missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Check for NaNs\n",
    "assert not pd.isna(X_train_imputed).any(), \"NaN values found in X_train after imputation\"\n",
    "assert not pd.isna(X_test_imputed).any(), \"NaN values found in X_test after imputation\"\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "X_train_imputed_normalized = scaler.fit_transform(X_train_imputed)\n",
    "X_test_imputed_normalized = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_imputed_normalized, y_train)\n",
    "\n",
    "# Check the distribution of the target variable after SMOTE\n",
    "print(\"Distribution of y_train before SMOTE:\", y_train.value_counts())\n",
    "print(\"Distribution of y_train after SMOTE:\", y_train_resampled.value_counts())\n",
    "\n",
    "# Training & Evaluating models\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(max_iter=1000), X_train_resampled, X_test_imputed_normalized),\n",
    "    'Random Forest': (RandomForestClassifier(), X_train_resampled, X_test_imputed_normalized),\n",
    "    'SVM': (SVC(probability=True), X_train_resampled, X_test_imputed_normalized),\n",
    "    'Gradient Boosted Trees (XGBoost)': (xgb.XGBClassifier(), X_train_resampled, X_test_normalized),\n",
    "    'Gradient Boosted Trees (LightGBM)': (lgb.LGBMClassifier(), X_train_resampled, X_test_normalized),\n",
    "    'Gradient Boosted Trees (CatBoost)': (CatBoostClassifier(silent=True), X_train_resampled, X_test_normalized)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, (model, X_train_model, X_test_model) in models.items():\n",
    "    model.fit(X_train_model, y_train_resampled)  \n",
    "    y_pred = model.predict(X_test_model)\n",
    "    y_prob = model.predict_proba(X_test_model)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    results[name] = [accuracy, precision, recall, auc]\n",
    "    print(f\"Results for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROC AUC Score:\", auc)\n",
    "    print(\"---------------------------\\n\")\n",
    "\n",
    "# Select model\n",
    "best_model_name = max(results, key=lambda k: results[k][3])\n",
    "best_model, _, _ = models[best_model_name]\n",
    "print(f\"The best model is: {best_model_name} with ROC AUC: {results[best_model_name][3]:.4f}\")\n",
    "\n",
    "# Ranking players by shooting ability using the best model\n",
    "players = df['playerId'].unique()\n",
    "player_goal_prob = {}\n",
    "\n",
    "for player in players:\n",
    "    player_shots = df[df['playerId'] == player].drop(columns=['shotResult', 'is_goal', 'playerId'])\n",
    "    \n",
    "    player_shots_imputed = imputer.transform(player_shots)\n",
    "    \n",
    "    player_shots_normalized = scaler.transform(player_shots_imputed)\n",
    "    \n",
    "    player_goal_prob[player] = best_model.predict_proba(player_shots_normalized)[:, 1].mean()\n",
    "\n",
    "sorted_players = sorted(player_goal_prob.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nPlayers ranked from best shooting ability to worst using the best model:\")\n",
    "for rank, (player, prob) in enumerate(sorted_players, 1):\n",
    "    print(f\"{rank}. Player {player} with average goal probability: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681a965f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29     0\n",
       "535    0\n",
       "695    0\n",
       "557    0\n",
       "836    0\n",
       "596    0\n",
       "165    0\n",
       "918    0\n",
       "495    1\n",
       "824    0\n",
       "65     0\n",
       "141    0\n",
       "925    0\n",
       "827    0\n",
       "655    0\n",
       "331    0\n",
       "664    0\n",
       "249    0\n",
       "907    0\n",
       "708    0\n",
       "305    0\n",
       "734    0\n",
       "975    1\n",
       "49     0\n",
       "896    0\n",
       "2      0\n",
       "544    0\n",
       "350    0\n",
       "904    0\n",
       "536    0\n",
       "344    0\n",
       "994    0\n",
       "481    0\n",
       "575    0\n",
       "33     0\n",
       "31     0\n",
       "231    0\n",
       "963    0\n",
       "192    0\n",
       "333    0\n",
       "3      0\n",
       "204    1\n",
       "514    0\n",
       "799    0\n",
       "306    0\n",
       "109    0\n",
       "430    0\n",
       "77     1\n",
       "84     0\n",
       "286    0\n",
       "82     0\n",
       "991    0\n",
       "789    0\n",
       "894    0\n",
       "398    0\n",
       "323    0\n",
       "519    0\n",
       "916    0\n",
       "922    0\n",
       "5      0\n",
       "731    0\n",
       "465    0\n",
       "97     0\n",
       "266    0\n",
       "357    0\n",
       "868    0\n",
       "798    0\n",
       "380    0\n",
       "631    0\n",
       "381    0\n",
       "490    0\n",
       "118    0\n",
       "900    1\n",
       "250    0\n",
       "523    0\n",
       "9      0\n",
       "196    0\n",
       "603    0\n",
       "81     0\n",
       "783    0\n",
       "587    0\n",
       "797    0\n",
       "239    0\n",
       "290    0\n",
       "211    0\n",
       "717    0\n",
       "359    0\n",
       "449    0\n",
       "227    0\n",
       "950    0\n",
       "946    0\n",
       "796    0\n",
       "501    0\n",
       "464    0\n",
       "362    0\n",
       "468    0\n",
       "935    0\n",
       "428    0\n",
       "7      0\n",
       "155    0\n",
       "541    0\n",
       "440    0\n",
       "482    0\n",
       "422    0\n",
       "778    0\n",
       "949    0\n",
       "334    0\n",
       "576    0\n",
       "934    0\n",
       "567    0\n",
       "594    0\n",
       "530    0\n",
       "581    0\n",
       "707    0\n",
       "448    0\n",
       "453    0\n",
       "228    0\n",
       "352    0\n",
       "728    0\n",
       "212    0\n",
       "79     0\n",
       "148    0\n",
       "302    0\n",
       "628    0\n",
       "777    0\n",
       "506    0\n",
       "342    0\n",
       "485    0\n",
       "711    0\n",
       "133    0\n",
       "703    0\n",
       "311    0\n",
       "722    0\n",
       "629    0\n",
       "0      0\n",
       "316    0\n",
       "706    0\n",
       "547    0\n",
       "872    0\n",
       "532    0\n",
       "477    0\n",
       "404    0\n",
       "172    0\n",
       "125    0\n",
       "394    0\n",
       "420    0\n",
       "552    0\n",
       "903    0\n",
       "90     0\n",
       "939    0\n",
       "181    0\n",
       "274    0\n",
       "895    0\n",
       "69     0\n",
       "291    0\n",
       "131    0\n",
       "300    0\n",
       "424    0\n",
       "326    0\n",
       "144    0\n",
       "423    0\n",
       "580    0\n",
       "135    0\n",
       "450    0\n",
       "164    1\n",
       "28     0\n",
       "773    0\n",
       "193    0\n",
       "388    0\n",
       "852    0\n",
       "169    1\n",
       "705    0\n",
       "140    0\n",
       "173    0\n",
       "6      0\n",
       "745    0\n",
       "478    0\n",
       "73     0\n",
       "910    0\n",
       "813    0\n",
       "238    0\n",
       "145    0\n",
       "792    0\n",
       "234    0\n",
       "220    0\n",
       "923    0\n",
       "500    0\n",
       "132    1\n",
       "990    0\n",
       "774    0\n",
       "185    0\n",
       "41     0\n",
       "696    0\n",
       "108    0\n",
       "588    1\n",
       "56     0\n",
       "405    0\n",
       "442    0\n",
       "757    0\n",
       "997    0\n",
       "24     0\n",
       "467    0\n",
       "539    0\n",
       "531    0\n",
       "618    0\n",
       "694    0\n",
       "926    0\n",
       "338    0\n",
       "51     0\n",
       "507    0\n",
       "516    0\n",
       "920    0\n",
       "781    0\n",
       "264    0\n",
       "817    0\n",
       "710    1\n",
       "682    0\n",
       "832    0\n",
       "518    0\n",
       "447    0\n",
       "18     0\n",
       "715    0\n",
       "483    0\n",
       "568    0\n",
       "433    0\n",
       "367    0\n",
       "83     0\n",
       "61     0\n",
       "638    0\n",
       "272    0\n",
       "285    0\n",
       "360    0\n",
       "354    0\n",
       "456    0\n",
       "278    0\n",
       "12     0\n",
       "182    0\n",
       "368    0\n",
       "881    0\n",
       "615    0\n",
       "223    0\n",
       "572    0\n",
       "970    0\n",
       "653    1\n",
       "545    0\n",
       "582    0\n",
       "633    0\n",
       "176    0\n",
       "665    0\n",
       "673    0\n",
       "585    0\n",
       "873    0\n",
       "393    0\n",
       "163    1\n",
       "248    0\n",
       "634    0\n",
       "885    0\n",
       "669    0\n",
       "375    0\n",
       "412    1\n",
       "74     0\n",
       "113    0\n",
       "598    0\n",
       "961    0\n",
       "390    0\n",
       "104    0\n",
       "114    0\n",
       "417    0\n",
       "525    1\n",
       "457    0\n",
       "409    0\n",
       "92     0\n",
       "930    0\n",
       "89     0\n",
       "336    0\n",
       "988    0\n",
       "921    0\n",
       "933    0\n",
       "605    0\n",
       "593    0\n",
       "611    1\n",
       "94     0\n",
       "11     0\n",
       "396    0\n",
       "533    0\n",
       "43     1\n",
       "42     0\n",
       "329    0\n",
       "167    0\n",
       "497    0\n",
       "876    0\n",
       "597    0\n",
       "756    1\n",
       "100    0\n",
       "426    0\n",
       "178    0\n",
       "444    0\n",
       "416    0\n",
       "870    0\n",
       "882    0\n",
       "680    0\n",
       "177    0\n",
       "395    0\n",
       "911    0\n",
       "793    0\n",
       "960    0\n",
       "684    0\n",
       "383    0\n",
       "956    0\n",
       "751    0\n",
       "257    0\n",
       "538    0\n",
       "335    0\n",
       "15     0\n",
       "324    0\n",
       "758    0\n",
       "222    0\n",
       "179    0\n",
       "983    0\n",
       "22     0\n",
       "356    0\n",
       "666    0\n",
       "861    0\n",
       "340    0\n",
       "431    0\n",
       "551    0\n",
       "833    0\n",
       "203    0\n",
       "630    0\n",
       "93     0\n",
       "558    1\n",
       "68     0\n",
       "622    0\n",
       "284    0\n",
       "844    0\n",
       "434    0\n",
       "153    0\n",
       "75     0\n",
       "730    0\n",
       "446    0\n",
       "188    0\n",
       "271    0\n",
       "236    1\n",
       "487    0\n",
       "117    0\n",
       "943    0\n",
       "512    0\n",
       "825    0\n",
       "591    0\n",
       "126    0\n",
       "116    0\n",
       "473    0\n",
       "693    0\n",
       "57     0\n",
       "863    0\n",
       "912    1\n",
       "369    1\n",
       "268    0\n",
       "46     0\n",
       "349    0\n",
       "195    0\n",
       "999    0\n",
       "834    0\n",
       "736    0\n",
       "263    0\n",
       "443    0\n",
       "675    0\n",
       "304    0\n",
       "341    0\n",
       "966    0\n",
       "149    0\n",
       "124    0\n",
       "786    0\n",
       "50     0\n",
       "353    0\n",
       "927    0\n",
       "142    0\n",
       "470    0\n",
       "399    0\n",
       "625    0\n",
       "320    0\n",
       "19     0\n",
       "809    0\n",
       "790    0\n",
       "808    0\n",
       "407    0\n",
       "537    0\n",
       "620    0\n",
       "38     0\n",
       "175    0\n",
       "245    0\n",
       "828    0\n",
       "667    0\n",
       "754    0\n",
       "858    0\n",
       "154    0\n",
       "287    0\n",
       "602    0\n",
       "569    0\n",
       "743    0\n",
       "17     0\n",
       "127    0\n",
       "322    0\n",
       "255    0\n",
       "657    0\n",
       "964    0\n",
       "190    0\n",
       "115    0\n",
       "616    0\n",
       "606    1\n",
       "180    0\n",
       "301    0\n",
       "759    0\n",
       "712    0\n",
       "723    0\n",
       "685    0\n",
       "979    0\n",
       "517    0\n",
       "984    0\n",
       "45     0\n",
       "909    0\n",
       "157    0\n",
       "851    0\n",
       "171    0\n",
       "16     0\n",
       "511    0\n",
       "48     0\n",
       "971    1\n",
       "940    0\n",
       "515    0\n",
       "952    0\n",
       "480    0\n",
       "283    0\n",
       "718    0\n",
       "877    0\n",
       "225    0\n",
       "26     0\n",
       "954    0\n",
       "437    0\n",
       "951    0\n",
       "364    0\n",
       "229    1\n",
       "37     0\n",
       "965    0\n",
       "374    0\n",
       "469    0\n",
       "967    0\n",
       "850    0\n",
       "704    0\n",
       "841    0\n",
       "194    0\n",
       "854    0\n",
       "864    0\n",
       "503    0\n",
       "969    0\n",
       "830    0\n",
       "579    0\n",
       "968    0\n",
       "162    0\n",
       "908    0\n",
       "152    0\n",
       "801    0\n",
       "993    0\n",
       "755    0\n",
       "111    0\n",
       "226    0\n",
       "688    0\n",
       "103    0\n",
       "421    0\n",
       "419    0\n",
       "750    0\n",
       "586    1\n",
       "780    0\n",
       "672    0\n",
       "119    0\n",
       "53     0\n",
       "151    0\n",
       "403    0\n",
       "945    0\n",
       "207    0\n",
       "658    0\n",
       "843    0\n",
       "762    0\n",
       "8      1\n",
       "807    0\n",
       "36     0\n",
       "452    0\n",
       "651    0\n",
       "253    0\n",
       "303    0\n",
       "746    0\n",
       "571    0\n",
       "623    0\n",
       "732    0\n",
       "891    0\n",
       "262    0\n",
       "610    1\n",
       "297    0\n",
       "414    0\n",
       "150    0\n",
       "788    0\n",
       "640    0\n",
       "889    0\n",
       "550    0\n",
       "886    0\n",
       "488    0\n",
       "147    0\n",
       "146    0\n",
       "720    0\n",
       "931    0\n",
       "739    0\n",
       "659    0\n",
       "348    0\n",
       "463    0\n",
       "325    0\n",
       "186    0\n",
       "123    0\n",
       "853    0\n",
       "608    0\n",
       "143    0\n",
       "958    0\n",
       "197    0\n",
       "609    0\n",
       "279    0\n",
       "293    0\n",
       "400    0\n",
       "122    0\n",
       "183    0\n",
       "202    0\n",
       "438    0\n",
       "246    0\n",
       "415    0\n",
       "932    0\n",
       "765    0\n",
       "906    0\n",
       "835    0\n",
       "887    0\n",
       "129    0\n",
       "637    0\n",
       "402    0\n",
       "784    0\n",
       "770    0\n",
       "735    0\n",
       "913    0\n",
       "219    0\n",
       "641    0\n",
       "915    0\n",
       "752    0\n",
       "806    1\n",
       "919    1\n",
       "624    0\n",
       "874    0\n",
       "760    1\n",
       "386    0\n",
       "972    0\n",
       "509    0\n",
       "267    0\n",
       "819    0\n",
       "441    0\n",
       "496    0\n",
       "112    0\n",
       "691    0\n",
       "232    0\n",
       "869    0\n",
       "607    0\n",
       "671    0\n",
       "373    0\n",
       "981    0\n",
       "842    0\n",
       "233    0\n",
       "785    0\n",
       "676    0\n",
       "317    0\n",
       "648    0\n",
       "410    0\n",
       "898    0\n",
       "709    1\n",
       "358    0\n",
       "258    0\n",
       "744    0\n",
       "627    0\n",
       "632    0\n",
       "282    0\n",
       "376    1\n",
       "384    0\n",
       "224    0\n",
       "953    0\n",
       "814    0\n",
       "472    0\n",
       "347    0\n",
       "505    0\n",
       "639    0\n",
       "987    0\n",
       "928    0\n",
       "905    0\n",
       "619    0\n",
       "855    0\n",
       "803    0\n",
       "645    0\n",
       "846    0\n",
       "556    0\n",
       "957    0\n",
       "577    1\n",
       "795    0\n",
       "85     0\n",
       "242    0\n",
       "698    0\n",
       "159    1\n",
       "524    0\n",
       "35     0\n",
       "540    0\n",
       "170    0\n",
       "654    0\n",
       "890    0\n",
       "857    0\n",
       "847    0\n",
       "944    0\n",
       "733    1\n",
       "95     0\n",
       "563    0\n",
       "240    0\n",
       "742    0\n",
       "574    0\n",
       "690    0\n",
       "460    0\n",
       "553    0\n",
       "888    0\n",
       "206    0\n",
       "392    0\n",
       "794    0\n",
       "397    0\n",
       "766    0\n",
       "848    0\n",
       "217    0\n",
       "4      0\n",
       "768    0\n",
       "642    0\n",
       "929    0\n",
       "612    0\n",
       "738    0\n",
       "546    0\n",
       "725    0\n",
       "683    0\n",
       "98     0\n",
       "804    0\n",
       "727    0\n",
       "573    0\n",
       "406    0\n",
       "502    0\n",
       "47     0\n",
       "32     0\n",
       "779    0\n",
       "839    0\n",
       "200    0\n",
       "134    0\n",
       "27     0\n",
       "880    0\n",
       "230    0\n",
       "489    0\n",
       "772    0\n",
       "378    0\n",
       "288    0\n",
       "418    0\n",
       "674    0\n",
       "391    0\n",
       "592    0\n",
       "498    0\n",
       "138    0\n",
       "62     0\n",
       "471    0\n",
       "647    0\n",
       "128    1\n",
       "976    0\n",
       "520    0\n",
       "838    0\n",
       "962    0\n",
       "64     0\n",
       "812    0\n",
       "14     0\n",
       "156    0\n",
       "40     0\n",
       "492    0\n",
       "379    0\n",
       "187    0\n",
       "763    0\n",
       "216    0\n",
       "791    0\n",
       "52     0\n",
       "878    0\n",
       "337    0\n",
       "748    0\n",
       "719    0\n",
       "724    0\n",
       "295    0\n",
       "701    0\n",
       "251    0\n",
       "726    0\n",
       "461    0\n",
       "455    0\n",
       "996    0\n",
       "815    0\n",
       "862    0\n",
       "269    0\n",
       "201    0\n",
       "161    0\n",
       "555    0\n",
       "729    0\n",
       "401    0\n",
       "702    0\n",
       "476    0\n",
       "821    0\n",
       "771    1\n",
       "105    0\n",
       "565    0\n",
       "389    0\n",
       "1      0\n",
       "937    0\n",
       "982    0\n",
       "561    0\n",
       "80     0\n",
       "205    0\n",
       "34     1\n",
       "775    0\n",
       "508    0\n",
       "427    1\n",
       "454    0\n",
       "366    0\n",
       "91     0\n",
       "339    0\n",
       "897    0\n",
       "564    0\n",
       "345    0\n",
       "776    0\n",
       "241    0\n",
       "13     0\n",
       "315    0\n",
       "600    0\n",
       "387    0\n",
       "273    0\n",
       "166    0\n",
       "840    1\n",
       "992    0\n",
       "646    0\n",
       "818    0\n",
       "484    0\n",
       "980    0\n",
       "504    0\n",
       "831    0\n",
       "243    0\n",
       "566    0\n",
       "875    0\n",
       "562    0\n",
       "686    0\n",
       "189    0\n",
       "782    0\n",
       "699    1\n",
       "475    0\n",
       "681    0\n",
       "510    0\n",
       "58     0\n",
       "474    0\n",
       "560    0\n",
       "856    0\n",
       "747    0\n",
       "252    0\n",
       "21     0\n",
       "313    0\n",
       "459    0\n",
       "160    0\n",
       "276    0\n",
       "955    0\n",
       "191    0\n",
       "385    0\n",
       "805    0\n",
       "413    0\n",
       "491    0\n",
       "343    0\n",
       "769    0\n",
       "308    0\n",
       "661    0\n",
       "130    0\n",
       "663    1\n",
       "871    0\n",
       "99     0\n",
       "372    0\n",
       "87     0\n",
       "458    0\n",
       "330    0\n",
       "214    0\n",
       "466    0\n",
       "121    0\n",
       "614    0\n",
       "20     0\n",
       "700    0\n",
       "71     0\n",
       "106    0\n",
       "270    0\n",
       "860    0\n",
       "435    0\n",
       "102    0\n",
       "Name: is_goal, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562116d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
